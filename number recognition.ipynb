{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = fetch_openml('mnist_784')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = mnist['data'],mnist['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "some_digit = x[36001]\n",
    "some_digit_image = some_digit.reshape(28,28)#as image pixels are given in 1d array so need to reshape\n",
    "plt.imshow(some_digit_image, cmap=matplotlib.cm.binary, interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   2.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   3.,   0.,   0.,   0.,   0.,   4.,\n",
       "         4.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   2.,   0.,  71., 164., 255., 111.,   0.,\n",
       "         6.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0., 163.,   0.,   4.,  97.,   0.,   5.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   4.,   0.,  54.,  50.,   0.,  86., 161.,\n",
       "         0.,   5.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   1.,\n",
       "         0.,  22., 143.,  78., 126., 119.,   0.,   3.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  25.,  52.,   0.,\n",
       "       122.,   0.,   3.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0., 127.,   0.,   3.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   4.,   0.,\n",
       "         6., 130.,   0.,   3.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   1.,   0.,  52., 178.,   0.,   6.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   8.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   2.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,  10.,   6.,   7.,   7.,   1.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_digit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[36001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=x[:70000]\n",
    "x_test =x[60000:]\n",
    "y_train, y_test = y[:70000],y[60000:]\n",
    "#shuffling train set\n",
    "shuffled_index = np.random.permutation(70000)\n",
    "x_train , y_train = x_train[shuffled_index],y_train[shuffled_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Creating 3 detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ..., False, False, False])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = y_train.astype(np.int8)\n",
    "y_test = y_test.astype(np.int8)\n",
    "y_train_3 = y_train==3\n",
    "y_test_3 = y_test==3\n",
    "y_test_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(tol=0.1,solver = 'lbfgs')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gmani\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(tol=0.1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clf.fit(x_train,y_train_3)\n",
    "clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \n",
    "0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 4.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 3.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.0, 22.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 109.0, 47.0, 127.0, 183.0, 186.0, 148.0, 10.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 77.0, 255.0, 90.0, 53.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 135.0, 0.0, 0.0, 0.0, 1.0, 5.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 136.0, 35.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 238.0, 146.0, 182.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.0, 0.0, 61.0, 87.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 97.0, 80.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 47.0, 200.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 15.0, 200.0, 175.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \n",
    "0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \n",
    "0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8], dtype=int8)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_digit = np.array(a)\n",
    "clf.predict([some_digit])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gmani\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\gmani\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\gmani\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.97231508, 0.97218532, 0.97145674])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(clf,x_train,y_train_3,cv=3,scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['filename.joblib']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "dump(clf, 'filename.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
